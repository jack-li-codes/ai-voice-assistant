"use client";

import { useEffect, useRef, useState } from "react";
import { getAIResponse } from "@/lib/gpt/getAIResponse";
import { speakWithElevenLabs, stopCurrentSpeech } from "@/lib/voice/speakWithElevenLabs";
import { toBilingual, hasChinese } from "@/lib/translate";
import { ChatMessage } from "@/lib/types/message";
import ManualInputBox from "./ManualInputBox";
import MicSelector from "./MicSelector";

declare global {
  interface Window {
    webkitSpeechRecognition: new () => SpeechRecognition;
    SpeechRecognition: new () => SpeechRecognition;
  }
  interface SpeechRecognition {
    lang: string;
    continuous: boolean;
    interimResults: boolean;
    start: () => void;
    stop: () => void;
    onresult: ((ev: SpeechRecognitionEvent) => any) | null;
    onend: ((ev: Event) => any) | null;
    onerror: ((ev: any) => any) | null;
  }
  interface SpeechRecognitionEvent extends Event {
    results: SpeechRecognitionResultList;
  }
}

/* ===================== Utils ===================== */
const hasCJK = (s: string) => /[\u3400-\u9FFF\uF900-\uFAFF]/.test(s);
const pickASRLang = (hint: string) => (hasCJK(hint) ? "zh-CN" : "en-US");
const isGreeting = (t: string) =>
  /^(hi|hello|hey|how are you|å“ˆ(å•°|ç½—)|ä½ å¥½)\b/i.test(t);

/** åˆ¤æ–­æ–‡æœ¬æ˜¯å¦æœ‰æ•ˆï¼ˆä¸æ˜¯ç©ºæ–‡æœ¬æˆ–åªæœ‰æ ‡ç‚¹ï¼‰ */
const isMeaningfulText = (t: string) => {
  const s = (t || "").trim();
  if (s.length < 2) return false; // é˜ˆå€¼å¯è°ƒ 2~5
  // åªæœ‰æ ‡ç‚¹/ç©ºç™½ä¹Ÿç®—æ— æ•ˆ
  if (/^[\s\W_]+$/.test(s)) return false;
  return true;
};

/** åˆ¤æ–­æ˜¯å¦æ˜¯æ—¶é—´æˆ³è¡Œï¼š---- HH:MM ---- */
const isTimestampLine = (text: string): boolean => {
  return /^----\s?\d{2}:\d{2}\s?----$/.test((text || "").trim());
};

/** ä»æ—¶é—´æˆ³è¡Œæå– HH:MM */
const extractHHMM = (text: string): string | null => {
  const match = (text || "").match(/(\d{2}:\d{2})/);
  return match ? match[1] : null;
};

/** ä» GUIDE ä¸­æå–â€œæˆ‘çš„åå­—â€ï¼ˆå¯è‹±æ–‡/ä¸­æ–‡ï¼‰ï¼Œæ‰¾ä¸åˆ°å°± null */
function extractNameFromGuide(guide: string): string | null {
  if (!guide) return null;
  const head = guide.split(/\r?\n/).slice(0, 60).join("\n");
  const patterns = [
    /my\s+name\s+is\s+([A-Z][a-zA-Z\-]+)/i,
    /i\s+am\s+([A-Z][a-zA-Z\-]+)/i,
    /name[:ï¼š]\s*([A-Z][a-zA-Z\-]+)/i,
    /ä½ å«[:ï¼š]?\s*([A-Za-z\u4e00-\u9fa5]+)/i,
    /æˆ‘æ˜¯[:ï¼š]?\s*([A-Za-z\u4e00-\u9fa5]+)/i,
  ];
  for (const re of patterns) {
    const m = head.match(re);
    if (m?.[1]) return m[1].trim();
  }
  return null;
}

/** ä¼°ç®—æ’­æŠ¥æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼šæ¯ç§’ ~2.2 è¯ + 300ms ä½™é‡ */
const estimateTtsMs = (text: string) => {
  const words = (text || "").trim().split(/\s+/).filter(Boolean).length;
  const ms = (words / 2.2) * 1000 + 300;
  return Math.max(800, Math.min(ms, 15000));
};

/** åªæ’­è‹±æ–‡ï¼šå»æ‰æ‰‹åŠ¨è¾“å…¥å›æ˜¾ & ä¸­æ–‡è¡Œ */
function sanitizeForTTS(reply: string, recentManuals: string[]) {
  let out = reply || "";
  for (const m of recentManuals) {
    const mm = (m || "").trim();
    if (mm.length >= 6 && out.includes(mm)) out = out.split(mm).join("");
  }
  if (hasCJK(out)) {
    out = out
      .split("\n")
      .filter((line) => !hasCJK(line))
      .join("\n")
      .trim();
  }
  return out || "Noted.";
}

/** â€”â€” æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆå›å£°è¿‡æ»¤ï¼‰ â€”â€” */
const normalize = (s: string) =>
  s.toLowerCase().replace(/[^a-z0-9\s]/g, " ").replace(/\s+/g, " ").trim();

const DROP = new Set([
  "a","an","the","to","and","of","for","on","in","at","by","that","this","it","is","are","was","were",
  "be","am","been","do","does","did","with","from","as","so","but","or","if","then","than","have","has","had",
  "i","you","we","they","he","she","my","your","our","their","me","us","him","her"
]);

const tokenSet = (s: string) => {
  const ts = normalize(s).split(" ").filter((x) => !!x);
  const set = new Set<string>();
  for (const t of ts) if (!DROP.has(t)) set.add(t);
  return set;
};

const jaccard = (setA: Set<string>, setB: Set<string>) => {
  let inter = 0;
  setA.forEach((token) => {
    if (setB.has(token)) inter++;
  });
  const union = setA.size + setB.size - inter;
  return union ? inter / union : 0;
};


function isEchoOfAI(partnerText: string, recentAI: string[], threshold = 0.55) {
  const a = tokenSet(partnerText);
  if (a.size < 3) return false;
  for (const r of recentAI) {
    const b = tokenSet(r);
    const sim = jaccard(a, b);
    if (sim >= threshold) return true;
  }
  return false;
}

/** è‡ªæˆ‘è¯­éŸ³è¿‡æ»¤ï¼šæ£€æµ‹ç”¨æˆ·æ˜¯å¦åœ¨è¯» AI åˆšæ‰çš„å»ºè®® (Live æ¨¡å¼ä¸“ç”¨) */
function isSimilarToLastAISuggestion(
  input: string,
  lastSuggested: string,
  lastSuggestedAt: number
): boolean {
  if (!lastSuggested) return false;

  // æ—¶é—´çª—å£ï¼š10 ç§’å†…
  if (Date.now() - lastSuggestedAt > 10000) return false;

  const t1 = normalize(input);
  const t2 = normalize(lastSuggested);

  // å¤ªçŸ­çš„è¾“å…¥ä¸åˆ¤æ–­
  if (t1.length < 10) return false;

  // åŒ…å«å…³ç³»ï¼šæ£€æŸ¥å‰ 20 ä¸ªå­—ç¬¦æ˜¯å¦åŒ¹é…
  const prefix = t2.slice(0, 20);
  if (prefix && t1.includes(prefix)) return true;

  // Jaccard ç›¸ä¼¼åº¦
  const set1 = tokenSet(input);
  const set2 = tokenSet(lastSuggested);
  const similarity = jaccard(set1, set2);

  return similarity > 0.7;
}

/** æ˜¯å¦æŠŠæˆ‘å«é”™ï¼ˆæ ¹æ®åŠ¨æ€ myNameï¼‰ */
function detectMisname(text: string, myName: string) {
  const name = (myName || "").trim();
  if (!name) return false;
  if (new RegExp(`\\b${name}\\b`, "i").test(text)) return false; // å·²å«å¯¹
  if (/\b(hi|hello|hey)[, ]+([A-Za-z\u4e00-\u9fa5]+)\b/i.test(text)) return true;
  return false;
}

/* ===================== Component ===================== */
// æ—¶é—´æˆ³é—´éš”å¸¸é‡ï¼ˆ5åˆ†é’Ÿï¼‰
const FIVE_MIN_MS = 5 * 60 * 1000;

export default function LiveConversation() {
  // â€”â€” è¡¨å• â€”â€” //
  const [mode, setMode] = useState("face-to-face");
  const [background, setBackground] = useState("");
  const [speakerRole, setSpeakerRole] = useState("");

  // Voice Output Mode: "LIVE" = ä½ è¯´ (TTS OFF), "AGENT" = AIè¯´ (TTS ON)
  const [voiceOutputMode, setVoiceOutputMode] = useState<"LIVE" | "AGENT">("LIVE");

  // UI æŠ˜å æ§åˆ¶
  const [showAdvanced, setShowAdvanced] = useState(false);

  // åŠ¨æ€èº«ä»½
  const [myName, setMyName] = useState("Lucy"); // é»˜è®¤å€¼ï¼Œéšæ—¶å¯æ”¹
  const [autoNameFromGuide, setAutoNameFromGuide] = useState(true);

  // å¤–æ”¾é˜²å›å£°æ¨¡å¼ï¼ˆæ‰“/æ¥ç”µè¯å»ºè®®å¼€å¯ï¼‰
  const [speakerMode, setSpeakerMode] = useState(true);

  // â€”â€” å¯¹è¯ä¸æ§åˆ¶ â€”â€” //
  const [conversation, setConversation] = useState<ChatMessage[]>([]);
  const [isActive, setIsActive] = useState(false);

  // Notes æ¨¡å¼ï¼šè‡ªåŠ¨æ—¶é—´æˆ³
  const lastTimestampRef = useRef<number>(0);

  // è¯†åˆ«/æ’­æŠ¥æ§åˆ¶
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const isSpeakingRef = useRef(false);
  const correctedOnceRef = useRef(false);
  const manualInputsRef = useRef<string[]>([]);
  const lastResultAtRef = useRef<number>(0);
  const heartbeatTimerRef = useRef<number | null>(null);

  // å¯åŠ¨æŠ–åŠ¨ä¿æŠ¤
  const startAtRef = useRef<number>(0);
  const silenceTimerRef = useRef<number | null>(null);

  // å›å£°è¿‡æ»¤ï¼šè®°å½•æœ€è¿‘ 3 æ¡ AI å›å¤
  const recentAIRef = useRef<string[]>([]);

  // åªå¤„ç†æœ€ç»ˆç»“æœï¼›é˜²é‡å¤
  const lastFinalTextRef = useRef<string>("");

  // æ’­æŠ¥åå¿½ç•¥çª—å£ï¼šé‡å¯è¯†åˆ«åçš„ä¸€å°æ®µæ—¶é—´å†…ä¸¢å¼ƒä»»ä½•ç»“æœ
  const listeningResumedAtRef = useRef<number>(0);
  const markListeningResumed = () => { listeningResumedAtRef.current = Date.now(); };

  // è‡ªæˆ‘è¯­éŸ³è¿‡æ»¤ï¼šè®°å½•æœ€è¿‘çš„ AI å»ºè®®æ–‡æœ¬ï¼ˆLive æ¨¡å¼ä¸“ç”¨ï¼‰
  const lastAISuggestedTextRef = useRef<string>("");
  const lastAISuggestedAtRef = useRef<number>(0);

  // æ ¹æ® GUIDE è‡ªåŠ¨æ›´æ–°åå­—ï¼ˆå¯å…³é—­ï¼‰
  useEffect(() => {
    if (!autoNameFromGuide) return;
    const n = extractNameFromGuide(background);
    if (n && n !== myName) setMyName(n);
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [background, autoNameFromGuide]);

  /* æ£€æŸ¥å¹¶æ’å…¥æ—¶é—´æˆ³ï¼ˆä»… Notes æ¨¡å¼ï¼‰ */
  const maybeInsertTimestamp = (forceIfAfter30s = false) => {
    if (mode !== "notes") return;

    const now = Date.now();
    const elapsed = now - lastTimestampRef.current;

    // ä»»åŠ¡ 2ï¼šæ‰‹åŠ¨æ’å…¥æ—¶é—´æˆ³ï¼ˆ30 ç§’é—´éš”é™åˆ¶ï¼‰
    if (forceIfAfter30s) {
      if (lastTimestampRef.current !== 0 && elapsed < 30000) {
        console.log("[Notes] è·ç¦»ä¸Šæ¬¡æ—¶é—´æˆ³ä¸è¶³ 30 ç§’ï¼Œè·³è¿‡æ’å…¥");
        return;
      }
      // ç»§ç»­æ‰§è¡Œæ’å…¥é€»è¾‘
    } else {
      // è‡ªåŠ¨æ’å…¥ï¼šé¦–æ¬¡æˆ–è¶…è¿‡ 5 åˆ†é’Ÿæ‰æ’å…¥
      if (lastTimestampRef.current !== 0 && elapsed < FIVE_MIN_MS) {
        return;
      }
    }

    // ç»Ÿä¸€çš„æ—¶é—´æˆ³æ’å…¥é€»è¾‘
    const timeStr = new Date(now).toLocaleTimeString("en-US", {
      hour: "2-digit",
      minute: "2-digit",
      hour12: false,
    });

    const timestampMsg: ChatMessage = {
      id: `timestamp-${now}`,
      role: "user", // ä½¿ç”¨ user roleï¼Œä½†é€šè¿‡å†…å®¹æ ¼å¼è¯†åˆ«
      contentEN: `---- ${timeStr} ----`,
      contentZH: `---- ${timeStr} ----`,
      timestamp: now,
    };

    setConversation((prev) => [...prev, timestampMsg]);
    lastTimestampRef.current = now;
  };

  /* ç»Ÿä¸€æäº¤å…¥å£ï¼šé˜²æ­¢ç©ºæäº¤äº§ç”Ÿ "noted" */
  const finalizeAndSubmit = async (text: string, reason: string) => {
    if (!isMeaningfulText(text)) {
      // æ— æ•ˆæ–‡æœ¬ï¼šä¸è¦å‘ GPTï¼Œä¸è¦ç”Ÿæˆ "noted"
      console.log("[ASR] skip submit (empty/short)", { reason, text });
      return;
    }

    // æ¸…ç†é™éŸ³è®¡æ—¶å™¨
    if (silenceTimerRef.current) {
      window.clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }

    // Notes æ¨¡å¼ï¼šåªåšå›å£°è¿‡æ»¤ï¼ˆæ›´å®½æ¾ï¼‰ï¼Œç„¶åä»…ä¿å­˜è½¬å†™ï¼Œä¸è°ƒç”¨ AI
    const isNotesMode = mode === "notes";

    if (isNotesMode) {
      // Notes æ¨¡å¼ä¸‹ä¹Ÿåšå›å£°è¿‡æ»¤ï¼Œé˜²æ­¢é‡å¤ä¿å­˜
      const echoThreshold = 0.50; // å®½æ¾é˜ˆå€¼
      if (isEchoOfAI(text, recentAIRef.current, echoThreshold)) {
        console.log("[Notes] skip (echo detected)", { reason, text });
        return;
      }

      // æ’å…¥æ—¶é—´æˆ³ï¼ˆå¦‚æœéœ€è¦ï¼‰
      maybeInsertTimestamp();

      // åªä¿å­˜è½¬å†™ï¼Œä¸è°ƒç”¨ AI
      const partnerBilingual = await toBilingual(text);
      const partnerMsg: ChatMessage = {
        id: `partner-${Date.now()}`,
        role: "user",
        contentEN: partnerBilingual.en,
        contentZH: partnerBilingual.zh,
        timestamp: Date.now(),
      };
      setConversation((prev) => [...prev, partnerMsg]);
      console.log("[Notes] transcript saved:", text);
      return; // ä¸è°ƒç”¨ AI
    }

    // é Notes æ¨¡å¼ï¼šå¸¸è§„å›å£°è¿‡æ»¤
    const echoThreshold = speakerMode ? 0.50 : 0.55;
    if (isEchoOfAI(text, recentAIRef.current, echoThreshold)) {
      console.log("[ASR] skip submit (echo detected)", { reason, text });
      return;
    }

    // Create bilingual message for partner's speech
    const partnerBilingual = await toBilingual(text);
    const partnerMsg: ChatMessage = {
      id: `partner-${Date.now()}`,
      role: "user",
      contentEN: partnerBilingual.en,
      contentZH: partnerBilingual.zh,
      timestamp: Date.now(),
    };
    setConversation((prev) => [...prev, partnerMsg]);

    // â€”â€” åå­—è¯¯å«ï¼Œä»…çº ä¸€æ¬¡ â€”â€” //
    const mustCorrectOnce = detectMisname(text, myName) && !correctedOnceRef.current;

    // â€”â€” è½»é‡ä¸Šä¸‹æ–‡ â€”â€” //
    const recent = conversation.slice(-4).map(msg =>
      `${msg.role === 'user' ? 'ğŸ§‘ Partner' : 'ğŸ¤– AI'}: ${msg.contentEN}`
    ).join("\n") || "(none)";

    // â€”â€” ç³»ç»Ÿæç¤ºï¼ˆåŠ¨æ€èº«ä»½ + è‹±æ–‡ + æ¨¡å¼åŒºåˆ†ï¼‰ â€”â€” //
    const persona = (myName || "Speaker").trim();
    const isLiveMode = voiceOutputMode === "LIVE";

    const systemMessage = isLiveMode
      ? `
You are my real-time conversation assistant. Provide natural English suggestions that I can say directly.
My name is "${persona}". Always write suggestions in FIRST PERSON as ${persona} (not as an AI).
Generate short, natural, spoken phrases (1-3 sentences) that sound like a real person talking.
If I lack information, suggest safe fallback phrases like:
- "I don't have the exact number in front of me, but I can follow up right after this."
- "Let me double-check that and get back to you."

NEVER mention AI, assistant, or reveal automated help. Sound completely natural.

GUIDE (context if present):
${background ? `"""\n${background}\n"""` : "(empty)"}

Context:
- Mode: ${mode || "N/A"}
- Counterparty: ${speakerRole || "N/A"}
`.trim()
      : `
You are my real-time voice proxy. Always reply in ENGLISH (even if inputs are Chinese).
Your persona name is "${persona}". NEVER claim to be anyone else.
If the partner misnames you, correct ONCE with: "Hi â€” this is ${persona}." then continue.
Do NOT reveal you are an assistant. Be natural, concise, professional (1â€“3 sentences).
Avoid repeating the same point; move the conversation forward with one crisp question or update.
Never echo my manual notes verbatim; paraphrase naturally.

GUIDE (verbatim if present):
${background ? `"""\n${background}\n"""` : "(empty)"}

Context:
- Mode: ${mode || "N/A"}
- Counterparty: ${speakerRole || "N/A"}
`.trim();

    const userMessage = isLiveMode
      ? `
Recent lines:
${recent}

Partner just said:
${text}

Task:
Generate ONLY what I should say next in ENGLISH (1-3 natural sentences, first-person as ${persona}).
Do not explain or add commentary. Just provide the suggested reply I can read aloud.
`.trim()
      : `
Recent lines:
${recent}

New partner line:
${text}

Task:
1) Reply in ENGLISH only, first-person as ${persona}, 1â€“3 sentences.
2) If this line is another greeting, transition to ONE concrete topic rather than repeating greetings.
3) Paraphrase; do not mirror the user's words.
`.trim();

    let finalUserMessage = userMessage;
    if (mustCorrectOnce) {
      finalUserMessage += `\nAlso: Begin with exactly: "Hi â€” this is ${persona}." once, then continue.`;
    }

    try {
      const reply = await getAIResponse({ systemMessage, userMessage: finalUserMessage });

      // è®°å½•æœ€è¿‘ 3 æ¡ AI å›å¤ï¼Œä¾›å›å£°è¿‡æ»¤
      recentAIRef.current = [reply, ...recentAIRef.current].slice(0, 3);

      // è‡ªæˆ‘è¯­éŸ³è¿‡æ»¤ï¼šåœ¨ Live æ¨¡å¼ä¸‹ä¿å­˜æ ‡å‡†åŒ–çš„ AI å»ºè®®
      if (isLiveMode) {
        lastAISuggestedTextRef.current = normalize(reply);
        lastAISuggestedAtRef.current = Date.now();
      }

      // Translate AI's English reply to Chinese
      const aiZH = await toBilingual(reply).then(b => b.zh);
      const aiMsg: ChatMessage = {
        id: `ai-${Date.now()}`,
        role: "assistant",
        contentEN: reply,
        contentZH: aiZH,
        timestamp: Date.now(),
      };
      setConversation((prev) => [...prev, aiMsg]);

      // â€”â€” æ’­æŠ¥çª—å£é”å®šï¼ˆä»… Agent æ¨¡å¼ï¼‰ â€”â€” //
      if (voiceOutputMode === "AGENT") {
        const recog2 = recognitionRef.current;
        const safeReply = sanitizeForTTS(reply, manualInputsRef.current);
        const speakMs = estimateTtsMs(safeReply);
        const extra = speakerMode ? 700 : 300;
        isSpeakingRef.current = true;
        try { recog2?.stop(); } catch {}
        await speakWithElevenLabs(safeReply);
        await new Promise((r) => setTimeout(r, speakMs + extra));
      }
      // Live æ¨¡å¼ï¼šä¸æ’­æŠ¥ï¼ŒAI åªæ˜¯ç”Ÿæˆå»ºè®®
    } catch (e) {
      console.error("âŒ generate/speak error:", e);
    } finally {
      isSpeakingRef.current = false;
      if (voiceOutputMode === "AGENT") {
        try { recognitionRef.current?.start(); markListeningResumed(); } catch {}
      }
    }

    if (mustCorrectOnce) correctedOnceRef.current = true;
  };

  /* è¯†åˆ«å™¨ */
  const ensureRecognition = () => {
    if (recognitionRef.current) return recognitionRef.current;

    const SR: any = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) {
      console.error("This browser does not support Web Speech API.");
      return null;
    }

    const recog: SpeechRecognition = new SR();
    recog.lang = "en-US";        // åˆå§‹å›ºå®šè‹±æ–‡
    recog.interimResults = true; // å…è®¸ä¸­é—´ç»“æœï¼Œä½†æˆ‘ä»¬åªåƒ isFinal
    recog.continuous = true;

    recog.onresult = async (event: SpeechRecognitionEvent) => {
      if (!isActive) return;
      if (isSpeakingRef.current) return;

      // æ’­æŠ¥åˆšç»“æŸåçš„å¿½ç•¥çª—å£ï¼ˆå¤–æ”¾ç¨é•¿ï¼‰
      const IGNORE_WINDOW_MS = speakerMode ? 1800 : 1200;
      if (Date.now() - listeningResumedAtRef.current < IGNORE_WINDOW_MS) return;

      // æ›´æ–°æ—¶é—´æˆ³å¹¶é‡ç½®é™éŸ³è®¡æ—¶å™¨
      lastResultAtRef.current = Date.now();

      // æ¸…ç†å¹¶é‡æ–°è®¾ç½®é™éŸ³è®¡æ—¶å™¨ï¼ˆ1s æ— æ–°ç»“æœï¼Œå¼ºåˆ¶æäº¤ï¼‰
      if (silenceTimerRef.current) {
        window.clearTimeout(silenceTimerRef.current);
      }

      // å–æœ€åä¸€ä¸ª isFinal=true çš„ç»“æœ
      let finalText = "";
      for (let i = event.results.length - 1; i >= 0; i--) {
        const res: any = event.results[i];
        if (res.isFinal) {
          finalText = res[0]?.transcript?.trim?.() || "";
          break;
        }
      }

      if (!finalText) {
        // å³ä½¿æ²¡æœ‰ final textï¼Œä¹Ÿè¦è®¾ç½®é™éŸ³è®¡æ—¶å™¨
        silenceTimerRef.current = window.setTimeout(() => {
          // 1s æ— æ–°ç»“æœï¼Œå°è¯•æäº¤ï¼ˆå¦‚æœæœ‰ç§¯ç´¯çš„ textï¼‰
          // è¿™é‡Œæˆ‘ä»¬æ²¡æœ‰ç§¯ç´¯æœºåˆ¶ï¼Œæ‰€ä»¥åªæ˜¯æ¸…ç†
          silenceTimerRef.current = null;
        }, 1000);
        return;
      }

      // å¯åŠ¨æŠ–åŠ¨ä¿æŠ¤ï¼šå¯åŠ¨å 800ms å†…çš„çŸ­æ–‡æœ¬ç›´æ¥å¿½ç•¥
      const now = Date.now();
      const warmup = now - startAtRef.current < 800;
      if (warmup && !isMeaningfulText(finalText)) {
        console.log("[ASR] warmup ignore:", finalText);
        return;
      }

      // è®¾ç½®é™éŸ³è®¡æ—¶å™¨
      silenceTimerRef.current = window.setTimeout(() => {
        // è¿™é‡Œä¸éœ€è¦å†æ¬¡æäº¤ï¼Œå› ä¸º finalText å·²ç»åœ¨ä¸‹é¢å¤„ç†äº†
        silenceTimerRef.current = null;
      }, 1000);

      // è‡ªæˆ‘è¯­éŸ³è¿‡æ»¤ï¼šåœ¨ Live æ¨¡å¼ä¸‹ï¼Œå¦‚æœç”¨æˆ·åœ¨è¯» AI çš„å»ºè®®ï¼Œä¸¢å¼ƒè¿™æ®µè¾“å…¥
      if (voiceOutputMode === "LIVE") {
        if (
          isSimilarToLastAISuggestion(
            finalText,
            lastAISuggestedTextRef.current,
            lastAISuggestedAtRef.current
          )
        ) {
          // é™é»˜ä¸¢å¼ƒï¼Œä¸åšä»»ä½•æç¤º
          return;
        }
      }

      // åªåŸºäºå½“å‰æ–‡æœ¬åˆ‡è¯­è¨€ï¼ˆå«ä¸­æ–‡æ‰åˆ‡ä¸­æ–‡ï¼‰
      const want = pickASRLang(finalText);
      if (recog.lang !== want) {
        try { recog.stop(); } catch {}
        recog.lang = want;
        try { recog.start(); markListeningResumed(); } catch {}
      }

      // å»é‡ï¼šå’Œä¸Šæ¬¡"æœ€ç»ˆæ–‡æœ¬"å‡ ä¹ä¸€è‡´å°±ä¸¢å¼ƒ
      const lastFinal = lastFinalTextRef.current;
      const almostSame =
        finalText === lastFinal ||
        (finalText.length > 5 &&
          lastFinal.length > 5 &&
          (finalText.startsWith(lastFinal) || lastFinal.startsWith(finalText)));
      if (almostSame) return;
      lastFinalTextRef.current = finalText;

      // è°ƒç”¨ç»Ÿä¸€æäº¤å…¥å£
      await finalizeAndSubmit(finalText, "onresult-final");
    };

    recog.onerror = (e: any) => {
      console.error("recognition.onerror:", e?.error || e);
    };

    recog.onend = () => {
      // æ¸…ç†é™éŸ³è®¡æ—¶å™¨
      if (silenceTimerRef.current) {
        window.clearTimeout(silenceTimerRef.current);
        silenceTimerRef.current = null;
      }
      // é‡å¯è¯†åˆ«ï¼ˆå¦‚æœè¿˜åœ¨æ´»è·ƒçŠ¶æ€ï¼‰
      if (isActive && !isSpeakingRef.current) {
        try { recognitionRef.current?.start(); markListeningResumed(); } catch {}
      }
    };

    recognitionRef.current = recog;
    return recog;
  };

  const safeStart = () => {
    startAtRef.current = Date.now(); // è®°å½•å¯åŠ¨æ—¶é—´
    if (silenceTimerRef.current) {
      window.clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
    try { ensureRecognition()?.start(); markListeningResumed(); } catch {}
  };
  const safeStop = () => {
    if (silenceTimerRef.current) {
      window.clearTimeout(silenceTimerRef.current);
      silenceTimerRef.current = null;
    }
    try { recognitionRef.current?.stop(); } catch {}
  };
  const destroyRecognition = () => {
    try {
      if (recognitionRef.current) {
        (recognitionRef.current as any).onresult = null;
        (recognitionRef.current as any).onend = null;
        (recognitionRef.current as any).onerror = null;
        try { recognitionRef.current.stop(); } catch {}
      }
    } finally { recognitionRef.current = null; }
  };

  // mic æƒé™ + å›å£°/é™å™ªï¼ˆå¤–æ”¾ä¹Ÿæœ‰å¸®åŠ©ï¼‰
  useEffect(() => {
    navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: false } as any
    })
      .then(() => console.log("ğŸ¤ mic granted"))
      .catch(() => alert("âŒ Microphone permission denied"));
  }, []);

  // å¿ƒè·³å…œåº•ï¼š20s æ— ç»“æœ -> å¼ºåˆ¶é‡å¯å¹¶åˆ‡å›è‹±æ–‡
  useEffect(() => {
    if (!isActive) return;
    lastResultAtRef.current = Date.now();
    heartbeatTimerRef.current = window.setInterval(() => {
      if (!isActive) return;
      const idleMs = Date.now() - lastResultAtRef.current;
      if (idleMs > 20000 && !isSpeakingRef.current) {
        try { recognitionRef.current?.stop(); } catch {}
        try {
          if (recognitionRef.current) (recognitionRef.current as any).lang = "en-US";
          recognitionRef.current?.start();
          markListeningResumed();
        } catch {}
      }
    }, 5000) as unknown as number;

    return () => {
      if (heartbeatTimerRef.current) {
        clearInterval(heartbeatTimerRef.current as number);
        heartbeatTimerRef.current = null;
      }
    };
  }, [isActive]);

  // å¼€/åœ
  useEffect(() => {
    if (isActive) {
      correctedOnceRef.current = false;
      recentAIRef.current = [];
      lastFinalTextRef.current = "";
      const recog = ensureRecognition();
      if (recog) (recog as any).lang = "en-US"; // å¯åŠ¨å›ºå®šè‹±æ–‡
      safeStart();
    } else {
      safeStop();
      destroyRecognition();
      // åœæ­¢å¯¹è¯æ—¶ï¼Œç«‹å³åœæ­¢ä»»ä½•æ­£åœ¨æ’­æ”¾çš„ TTS
      stopCurrentSpeech();

      // ä»»åŠ¡ 3ï¼šStop æ—¶é‡ç½® Notes ä¼šè¯çŠ¶æ€
      if (mode === "notes") {
        lastTimestampRef.current = 0;
      }
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive]);

  // å¯¼å‡ºå¯¹è¯è®°å½•ä¸º .txt æ–‡ä»¶
  const exportConversation = () => {
    if (conversation.length === 0) return;

    // Format bilingual messages for export
    const content = conversation.map(msg => {
      // æ—¶é—´æˆ³æ¶ˆæ¯
      if (isTimestampLine(msg.contentEN)) {
        return `\n${msg.contentEN}\n`;
      }

      const role = msg.role === "user" ? "ğŸ§‘ You" : "ğŸ¤– AI";
      const isChinese = hasChinese(msg.contentZH);
      // Show original language first, then translation
      if (isChinese) {
        return `${role} (ZH): ${msg.contentZH}\n${role} (EN): ${msg.contentEN}`;
      } else {
        return `${role} (EN): ${msg.contentEN}\n${role} (ZH): ${msg.contentZH}`;
      }
    }).join("\n\n");

    // ç”Ÿæˆæ—¶é—´æˆ³ï¼š2025-11-24-16-30-05 æ ¼å¼
    const now = new Date();
    const timestamp = now
      .toISOString()
      .replace(/T/, "-")
      .replace(/:/g, "-")
      .split(".")[0];

    const blob = new Blob([content], { type: "text/plain;charset=utf-8" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.href = url;
    a.download = `ai-secretary-conversation-${timestamp}.txt`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);

    URL.revokeObjectURL(url);
  };

  // å¯¼å‡ºå¯¹è¯è®°å½•ä¸º .md æ–‡ä»¶ï¼ˆMarkdown æ ¼å¼ï¼Œä»… Notes æ¨¡å¼ï¼‰
  const exportConversationMarkdown = () => {
    if (conversation.length === 0) return;

    const now = new Date();
    const dateStr = now.toISOString().split("T")[0]; // YYYY-MM-DD
    const timestamp = now
      .toISOString()
      .replace(/T/, "-")
      .replace(/:/g, "-")
      .split(".")[0];

    // Markdown header
    let content = `# AI Secretary â€“ Notes\nDate: ${dateStr}\n\n`;

    // å½“å‰æ—¶é—´æˆ³æ ‡é¢˜ï¼ˆç”¨äºåˆ†ç»„ï¼‰
    let currentTimeHeader = "";

    conversation.forEach((msg) => {
      // æ—¶é—´æˆ³æ¶ˆæ¯ï¼šæå–æ—¶é—´å¹¶è®¾ä¸ºæ–°çš„ section header
      if (isTimestampLine(msg.contentEN)) {
        const time = extractHHMM(msg.contentEN);
        if (time) {
          currentTimeHeader = time;
          content += `\n## ${currentTimeHeader}\n\n`;
        }
        return;
      }

      // å¦‚æœè¿˜æ²¡æœ‰æ—¶é—´æˆ³ headerï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤çš„
      if (!currentTimeHeader) {
        currentTimeHeader = "Session";
        content += `## ${currentTimeHeader}\n\n`;
      }

      // Transcript æ¶ˆæ¯
      if (msg.role === "user") {
        const isChinese = hasChinese(msg.contentZH);
        // åŒè¯­ bullet points
        if (isChinese) {
          content += `- ğŸ‡¨ğŸ‡³ ${msg.contentZH}\n`;
          content += `- ğŸ‡ºğŸ‡¸ ${msg.contentEN}\n`;
        } else {
          content += `- ğŸ‡ºğŸ‡¸ ${msg.contentEN}\n`;
          content += `- ğŸ‡¨ğŸ‡³ ${msg.contentZH}\n`;
        }
        content += "\n";
      }
      // AI æ¶ˆæ¯ï¼ˆNotes æ¨¡å¼ä¸‹é€šå¸¸æ²¡æœ‰ï¼Œä½†ä¸ºäº†å®Œæ•´æ€§ä¿ç•™ï¼‰
      else if (msg.role === "assistant") {
        content += `**AI Reply:**\n- ğŸ‡ºğŸ‡¸ ${msg.contentEN}\n- ğŸ‡¨ğŸ‡³ ${msg.contentZH}\n\n`;
      }
    });

    const blob = new Blob([content], { type: "text/markdown;charset=utf-8" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.href = url;
    a.download = `ai-secretary-notes-${timestamp}.md`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);

    URL.revokeObjectURL(url);
  };

  // æ‰‹åŠ¨è¾“å…¥ï¼šä¸æ’­æŠ¥æ‰‹åŠ¨æ–‡æœ¬
  const handleManualSend = async (text: string) => {
    if (!text?.trim()) return;

    // Notes æ¨¡å¼ï¼šæ’å…¥æ—¶é—´æˆ³ï¼ˆå¦‚æœéœ€è¦ï¼‰
    const isNotesMode = mode === "notes";
    if (isNotesMode) {
      maybeInsertTimestamp();
    }

    // Create bilingual message for manual input
    const manualBilingual = await toBilingual(text);
    const manualMsg: ChatMessage = {
      id: `manual-${Date.now()}`,
      role: "user",
      contentEN: manualBilingual.en,
      contentZH: manualBilingual.zh,
      timestamp: Date.now(),
      isManual: true,
    };
    setConversation((prev) => [...prev, manualMsg]);
    manualInputsRef.current = [text, ...manualInputsRef.current].slice(0, 5);

    // Notes æ¨¡å¼ï¼šä»…ä¿å­˜æ‰‹åŠ¨è¾“å…¥ï¼Œä¸è°ƒç”¨ AI
    if (isNotesMode) {
      console.log("[Notes] manual input saved:", text);
      return; // ä¸è°ƒç”¨ AI
    }

    const recent = conversation.slice(-4).map(msg =>
      `${msg.role === 'user' ? `ğŸ§‘ ${myName || "Me"}` : 'ğŸ¤– AI'}: ${msg.contentEN}`
    ).join("\n") || "(none)";

    const persona = (myName || "Speaker").trim();
    const isLiveMode = voiceOutputMode === "LIVE";

    const systemMessage = isLiveMode
      ? `
You are my real-time conversation assistant. Provide natural English suggestions that I can say directly.
My name is "${persona}". Always write suggestions in FIRST PERSON as ${persona} (not as an AI).
Generate short, natural, spoken phrases (1-3 sentences) based on my notes.
NEVER mention AI, assistant, or reveal automated help. Sound completely natural.
`.trim()
      : `
You are my real-time voice proxy. Always reply in ENGLISH (even if inputs are Chinese).
Your persona name is "${persona}". Never claim to be anyone else.
Be natural, concise, professional (1â€“3 sentences). Progress the talk with one crisp point.
Do not echo my manual note verbatim; paraphrase.
`.trim();

    const userMessage = isLiveMode
      ? `
Recent lines:
${recent}

My manual note:
${text}

Task:
Generate ONLY what I should say next in ENGLISH (1-3 natural sentences, first-person as ${persona}).
Paraphrase my note naturally. Do not explain or add commentary.
`.trim()
      : `
Recent lines:
${recent}

My manual note:
${text}

Task:
1) Reply in English only, first-person as ${persona}, 1â€“3 sentences.
2) Paraphrase my note; don't mirror wording.
3) Ask one precise follow-up if helpful.
`.trim();

    try {
      const reply = await getAIResponse({ systemMessage, userMessage });
      recentAIRef.current = [reply, ...recentAIRef.current].slice(0, 3);

      // è‡ªæˆ‘è¯­éŸ³è¿‡æ»¤ï¼šåœ¨ Live æ¨¡å¼ä¸‹ä¿å­˜æ ‡å‡†åŒ–çš„ AI å»ºè®®
      if (isLiveMode) {
        lastAISuggestedTextRef.current = normalize(reply);
        lastAISuggestedAtRef.current = Date.now();
      }

      // Translate AI's English reply to Chinese
      const aiZH = await toBilingual(reply).then(b => b.zh);
      const aiMsg: ChatMessage = {
        id: `ai-manual-${Date.now()}`,
        role: "assistant",
        contentEN: reply,
        contentZH: aiZH,
        timestamp: Date.now(),
      };
      setConversation((prev) => [...prev, aiMsg]);

      // æ’­æŠ¥ï¼ˆä»… Agent æ¨¡å¼ï¼‰
      if (voiceOutputMode === "AGENT") {
        const recog = ensureRecognition();
        isSpeakingRef.current = true;
        try { recog?.stop(); } catch {}
        const safeReply = sanitizeForTTS(reply, manualInputsRef.current);
        const speakMs = estimateTtsMs(safeReply);
        const extra = speakerMode ? 700 : 300;
        await speakWithElevenLabs(safeReply);
        await new Promise((r) => setTimeout(r, speakMs + extra));
      }
      // Live æ¨¡å¼ï¼šä¸æ’­æŠ¥
    } catch (e) {
      console.error(e);
    } finally {
      isSpeakingRef.current = false;
      if (isActive && voiceOutputMode === "AGENT") safeStart();
    }
  };

  return (
    <div className="p-4 space-y-4">
      <h2 className="text-xl font-semibold">AI Secretary â€” Live Conversation</h2>

      {/* æ ¸å¿ƒè®¾ç½® */}
      <div className="border rounded p-3 bg-gray-50">
        <MicSelector
          className="mb-3"
          onSelected={(id) => {
            console.log("Preferred mic deviceId:", id);
          }}
        />

        <div className="grid gap-3 md:grid-cols-3 mb-3">
          <div>
            <label className="block text-sm mb-1 font-medium">Mode åœºæ™¯</label>
            <select
              className="w-full border rounded px-2 py-1"
              value={mode}
              onChange={(e) => setMode(e.target.value)}
              disabled={isActive}
            >
              <option value="face-to-face">Face to Face å½“é¢æ²Ÿé€š</option>
              <option value="call-out">Call Out (future)</option>
              <option value="call-in">Call In (future)</option>
              <option value="notes">Notes (Silent Transcript)</option>
            </select>
          </div>

          <div>
            <label className="block text-sm mb-1 font-medium">Voice Output è¯­éŸ³è¾“å‡º</label>
            <div className="flex items-center h-8">
              {mode === "notes" ? (
                <span className="text-sm text-gray-600 italic">
                  Notes mode: text only ğŸ“
                </span>
              ) : (
                <label className="inline-flex items-center gap-2 cursor-pointer">
                  <input
                    type="checkbox"
                    checked={voiceOutputMode === "AGENT"}
                    onChange={(e) => setVoiceOutputMode(e.target.checked ? "AGENT" : "LIVE")}
                    disabled={isActive}
                    className="w-4 h-4"
                  />
                  <span className="text-sm">
                    {voiceOutputMode === "AGENT" ? "ON (AI speaks)" : "OFF (you speak)"}
                  </span>
                </label>
              )}
            </div>
          </div>

          <div className="flex items-end">
            <button
              className={`w-full px-3 py-2 rounded text-white font-medium ${isActive ? "bg-red-500 hover:bg-red-600" : "bg-green-600 hover:bg-green-700"}`}
              onClick={() => setIsActive((v) => !v)}
            >
              {isActive ? "åœæ­¢ Stop" : "å¼€å§‹ Start"}
            </button>
          </div>
        </div>

        {/* Advanced æŠ˜å åŒº */}
        <details className="mt-2">
          <summary className="cursor-pointer text-sm text-gray-600 hover:text-gray-800 font-medium">
            Advanced Settings é«˜çº§è®¾ç½® â–¼
          </summary>
          <div className="mt-3 grid gap-3 md:grid-cols-2 border-t pt-3">
            <div>
              <label className="block text-sm mb-1">My Name æˆ‘çš„èº«ä»½</label>
              <input
                className="w-full border rounded px-2 py-1 text-sm"
                placeholder="e.g. James' father"
                value={myName}
                onChange={(e) => setMyName(e.target.value)}
                disabled={isActive || autoNameFromGuide}
              />
              <label className="inline-flex items-center gap-2 mt-1 text-xs">
                <input
                  type="checkbox"
                  checked={autoNameFromGuide}
                  onChange={(e) => setAutoNameFromGuide(e.target.checked)}
                  disabled={isActive}
                />
                Auto from GUIDE
              </label>
            </div>

            <div>
              <label className="block text-sm mb-1">Counterparty å¯¹æ–¹èº«ä»½</label>
              <input
                className="w-full border rounded px-2 py-1 text-sm"
                placeholder="e.g. ER doctor"
                value={speakerRole}
                onChange={(e) => setSpeakerRole(e.target.value)}
                disabled={isActive}
              />
            </div>

            <div className="md:col-span-2">
              <label className="inline-flex items-center gap-2 text-sm">
                <input
                  type="checkbox"
                  checked={speakerMode}
                  onChange={(e) => setSpeakerMode(e.target.checked)}
                  disabled={isActive}
                />
                Speakerphone Mode (Echo Shield) æ‰¬å£°å™¨æ¨¡å¼ï¼ˆé˜²å›å£°ï¼‰
              </label>
            </div>
          </div>
        </details>
      </div>

      <div>
        <label className="block text-sm mb-1 font-medium">GUIDE / Background èƒŒæ™¯è¯´æ˜</label>

        {/* æ–‡ä»¶ä¸Šä¼ æ§ä»¶ */}
        <div className="mb-2">
          <input
            type="file"
            accept=".txt,.md,.rtf,.text"
            className="text-sm"
            onChange={(e) => {
              const file = e.target.files?.[0];
              if (!file) return;

              const reader = new FileReader();
              reader.onload = (event) => {
                let raw = String(event.target?.result || "");

                // ç»Ÿä¸€æ¢è¡Œç¬¦
                raw = raw.replace(/\r\n/g, "\n");
                // å»æ‰ BOM
                raw = raw.replace(/^\uFEFF/, "");

                // æŒ‰ç©ºè¡Œåˆ†æ®µ
                const parts = raw.split(/\n\s*\n/);
                let cleaned: string;
                if (parts.length > 1) {
                  // è·³è¿‡ç¬¬ä¸€æ®µï¼ˆæ ‡é¢˜ï¼‰ï¼Œä½¿ç”¨åé¢çš„æ­£æ–‡
                  cleaned = parts.slice(1).join("\n\n").trimStart();
                } else {
                  // æ²¡æœ‰ç©ºè¡Œï¼Œé€€åŒ–ä¸ºåŸæ¥çš„è¡Œä¸º
                  cleaned = raw.trimStart();
                }

                setBackground(cleaned);
              };
              reader.onerror = () => {
                alert("æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚");
              };
              reader.readAsText(file, "utf-8");

              // æ¸…ç©º inputï¼Œå…è®¸é‡å¤ä¸Šä¼ åŒä¸€æ–‡ä»¶
              e.target.value = "";
            }}
            disabled={isActive}
          />
          <p className="text-xs text-gray-500 mt-1">
            å¯é€‰æ‹©æœ¬åœ° .txt/.md/.rtf æ–‡ä»¶å¯¼å…¥ç—…æƒ…/èƒŒæ™¯è¯´æ˜
          </p>
        </div>

        <textarea
          className="w-full border rounded px-2 py-2 h-32"
          placeholder="åœ¨è¿™é‡Œç®€è¦å†™æ˜ç—…æƒ…æˆ–èƒŒæ™¯ï¼ŒAI ä¼šæŒ‰ç…§è¿™é‡Œçš„å†…å®¹æ¥å›ç­”ã€‚ä¹Ÿå¯ä»¥ä¸Šæ–¹å¯¼å…¥ .txt æ–‡ä»¶ã€‚ / Briefly describe the situation here, or import a .txt file above."
          value={background}
          onChange={(e) => setBackground(e.target.value)}
          disabled={isActive}
        />
      </div>

      <div className="flex items-center justify-between mb-2">
        <h3 className="text-sm font-medium">å¯¹è¯è®°å½• Conversation</h3>
        <div className="flex gap-2">
          {/* ä»»åŠ¡ 2ï¼šæ‰‹åŠ¨æ’å…¥æ—¶é—´æˆ³æŒ‰é’®ï¼ˆä»… Notes æ¨¡å¼ï¼‰ */}
          {mode === "notes" && (
            <button
              className="px-3 py-1 rounded text-sm bg-yellow-500 text-white hover:bg-yellow-600"
              onClick={() => maybeInsertTimestamp(true)}
            >
              ğŸ•’ Insert Timestamp
            </button>
          )}
          <button
            className="px-3 py-1 rounded text-sm bg-blue-500 text-white hover:bg-blue-600 disabled:opacity-50 disabled:cursor-not-allowed"
            onClick={exportConversation}
            disabled={conversation.length === 0}
          >
            å¯¼å‡ºä¸ºæ–‡æœ¬ Export .txt
          </button>
          {mode === "notes" && (
            <button
              className="px-3 py-1 rounded text-sm bg-green-500 text-white hover:bg-green-600 disabled:opacity-50 disabled:cursor-not-allowed"
              onClick={exportConversationMarkdown}
              disabled={conversation.length === 0}
            >
              å¯¼å‡º Markdown Export .md
            </button>
          )}
        </div>
      </div>

      <div className="border rounded p-3 bg-white">
        {conversation.map((msg, idx) => {
          // æ—¶é—´æˆ³æ¶ˆæ¯ç‰¹æ®Šå¤„ç†
          if (isTimestampLine(msg.contentEN)) {
            // ä»»åŠ¡ 1ï¼šæå–å¹¶ä¼˜åŒ–æ—¶é—´æˆ³æ˜¾ç¤º
            const timeStr = extractHHMM(msg.contentEN);
            return (
              <div key={msg.id || idx} className="my-4 text-center">
                <div className="inline-block px-4 py-1 bg-gray-200 text-gray-700 rounded-full text-sm font-medium">
                  ğŸ•’ {timeStr || msg.contentEN}
                </div>
              </div>
            );
          }

          const isUser = msg.role === "user";
          const isAI = msg.role === "assistant";
          const isChinese = hasChinese(msg.contentZH);
          const isLiveMode = voiceOutputMode === "LIVE";
          const isNotesMode = mode === "notes";

          // Determine display order: original first, then translation
          let firstLang: string, firstContent: string;
          let secondLang: string, secondContent: string;

          if (isAI) {
            // AI messages: always EN first, then ZH
            firstLang = "EN";
            firstContent = msg.contentEN;
            secondLang = "ZH";
            secondContent = msg.contentZH;
          } else {
            // User messages: original language first
            if (isChinese) {
              firstLang = "ZH";
              firstContent = msg.contentZH;
              secondLang = "EN";
              secondContent = msg.contentEN;
            } else {
              firstLang = "EN";
              firstContent = msg.contentEN;
              secondLang = "ZH";
              secondContent = msg.contentZH;
            }
          }

          // Notes æ¨¡å¼ï¼šæ·»åŠ  ğŸ“ å›¾æ ‡
          const roleLabel = isNotesMode && isUser
            ? (msg.isManual ? `ğŸ“ ${myName || "You"} (manual)` : "ğŸ“ Transcript")
            : isUser
            ? (msg.isManual ? `ğŸ§‘ ${myName || "You"} (manual)` : "ğŸ§‘ Partner")
            : (isLiveMode ? "ğŸ’¡ Suggested Reply" : "ğŸ¤– AI");

          return (
            <div key={msg.id || idx} className="mb-3 leading-7">
              {isAI && isLiveMode ? (
                // Live æ¨¡å¼ï¼šç®€æ´æ˜¾ç¤ºï¼Œåƒ notes
                <>
                  <div className="font-medium text-blue-700 mb-1">
                    {roleLabel}:
                  </div>
                  <div className="whitespace-pre-wrap pl-4 border-l-2 border-blue-300 text-gray-800">
                    {firstContent}
                  </div>
                  {/* ä¸­æ–‡æŠ˜å æ˜¾ç¤ºï¼ˆå¯é€‰ï¼‰ */}
                  <details className="mt-2 pl-4 text-sm">
                    <summary className="cursor-pointer text-gray-500 hover:text-gray-700">
                      Show Chinese æ˜¾ç¤ºä¸­æ–‡
                    </summary>
                    <div className="whitespace-pre-wrap text-gray-600 mt-1">
                      {secondContent}
                    </div>
                  </details>
                </>
              ) : isNotesMode && isUser ? (
                // Notes æ¨¡å¼ï¼šç®€æ´åŒè¯­æ˜¾ç¤º
                <>
                  <div className="whitespace-pre-wrap">
                    {roleLabel} ({firstLang}): {firstContent}
                  </div>
                  <div className="whitespace-pre-wrap text-gray-600">
                    {roleLabel} ({secondLang}): {secondContent}
                  </div>
                </>
              ) : (
                // Agent æ¨¡å¼æˆ–å…¶ä»–ï¼šä¿æŒç°æœ‰æ ·å¼
                <>
                  <div className="whitespace-pre-wrap">
                    {roleLabel} ({firstLang}): {firstContent}
                  </div>
                  <div className="whitespace-pre-wrap text-gray-600">
                    {roleLabel} ({secondLang}): {secondContent}
                  </div>
                </>
              )}
            </div>
          );
        })}
      </div>

      <ManualInputBox onSend={handleManualSend} />
    </div>
  );
}
