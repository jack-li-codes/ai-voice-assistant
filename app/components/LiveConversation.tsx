"use client";

import { useEffect, useRef, useState } from "react";
import { getAIResponse } from "@/lib/gpt/getAIResponse";
import { speakWithElevenLabs } from "@/lib/voice/speakWithElevenLabs";
import { toBilingual, hasChinese } from "@/lib/translate";
import { ChatMessage } from "@/lib/types/message";
import ManualInputBox from "./ManualInputBox";

declare global {
  interface Window {
    webkitSpeechRecognition: new () => SpeechRecognition;
    SpeechRecognition: new () => SpeechRecognition;
  }
  interface SpeechRecognition {
    lang: string;
    continuous: boolean;
    interimResults: boolean;
    start: () => void;
    stop: () => void;
    onresult: ((ev: SpeechRecognitionEvent) => any) | null;
    onend: ((ev: Event) => any) | null;
    onerror: ((ev: any) => any) | null;
  }
  interface SpeechRecognitionEvent extends Event {
    results: SpeechRecognitionResultList;
  }
}

/* ===================== Utils ===================== */
const hasCJK = (s: string) => /[\u3400-\u9FFF\uF900-\uFAFF]/.test(s);
const pickASRLang = (hint: string) => (hasCJK(hint) ? "zh-CN" : "en-US");
const isGreeting = (t: string) =>
  /^(hi|hello|hey|how are you|å“ˆ(å•°|ç½—)|ä½ å¥½)\b/i.test(t);

/** ä» GUIDE ä¸­æå–â€œæˆ‘çš„åå­—â€ï¼ˆå¯è‹±æ–‡/ä¸­æ–‡ï¼‰ï¼Œæ‰¾ä¸åˆ°å°± null */
function extractNameFromGuide(guide: string): string | null {
  if (!guide) return null;
  const head = guide.split(/\r?\n/).slice(0, 60).join("\n");
  const patterns = [
    /my\s+name\s+is\s+([A-Z][a-zA-Z\-]+)/i,
    /i\s+am\s+([A-Z][a-zA-Z\-]+)/i,
    /name[:ï¼š]\s*([A-Z][a-zA-Z\-]+)/i,
    /ä½ å«[:ï¼š]?\s*([A-Za-z\u4e00-\u9fa5]+)/i,
    /æˆ‘æ˜¯[:ï¼š]?\s*([A-Za-z\u4e00-\u9fa5]+)/i,
  ];
  for (const re of patterns) {
    const m = head.match(re);
    if (m?.[1]) return m[1].trim();
  }
  return null;
}

/** ä¼°ç®—æ’­æŠ¥æ—¶é•¿ï¼ˆæ¯«ç§’ï¼‰ï¼šæ¯ç§’ ~2.2 è¯ + 300ms ä½™é‡ */
const estimateTtsMs = (text: string) => {
  const words = (text || "").trim().split(/\s+/).filter(Boolean).length;
  const ms = (words / 2.2) * 1000 + 300;
  return Math.max(800, Math.min(ms, 15000));
};

/** åªæ’­è‹±æ–‡ï¼šå»æ‰æ‰‹åŠ¨è¾“å…¥å›æ˜¾ & ä¸­æ–‡è¡Œ */
function sanitizeForTTS(reply: string, recentManuals: string[]) {
  let out = reply || "";
  for (const m of recentManuals) {
    const mm = (m || "").trim();
    if (mm.length >= 6 && out.includes(mm)) out = out.split(mm).join("");
  }
  if (hasCJK(out)) {
    out = out
      .split("\n")
      .filter((line) => !hasCJK(line))
      .join("\n")
      .trim();
  }
  return out || "Noted.";
}

/** â€”â€” æ–‡æœ¬ç›¸ä¼¼åº¦ï¼ˆå›å£°è¿‡æ»¤ï¼‰ â€”â€” */
const normalize = (s: string) =>
  s.toLowerCase().replace(/[^a-z0-9\s]/g, " ").replace(/\s+/g, " ").trim();

const DROP = new Set([
  "a","an","the","to","and","of","for","on","in","at","by","that","this","it","is","are","was","were",
  "be","am","been","do","does","did","with","from","as","so","but","or","if","then","than","have","has","had",
  "i","you","we","they","he","she","my","your","our","their","me","us","him","her"
]);

const tokenSet = (s: string) => {
  const ts = normalize(s).split(" ").filter((x) => !!x);
  const set = new Set<string>();
  for (const t of ts) if (!DROP.has(t)) set.add(t);
  return set;
};

const jaccard = (setA: Set<string>, setB: Set<string>) => {
  let inter = 0;
  setA.forEach((token) => {
    if (setB.has(token)) inter++;
  });
  const union = setA.size + setB.size - inter;
  return union ? inter / union : 0;
};


function isEchoOfAI(partnerText: string, recentAI: string[], threshold = 0.55) {
  const a = tokenSet(partnerText);
  if (a.size < 3) return false;
  for (const r of recentAI) {
    const b = tokenSet(r);
    const sim = jaccard(a, b);
    if (sim >= threshold) return true;
  }
  return false;
}

/** æ˜¯å¦æŠŠæˆ‘å«é”™ï¼ˆæ ¹æ®åŠ¨æ€ myNameï¼‰ */
function detectMisname(text: string, myName: string) {
  const name = (myName || "").trim();
  if (!name) return false;
  if (new RegExp(`\\b${name}\\b`, "i").test(text)) return false; // å·²å«å¯¹
  if (/\b(hi|hello|hey)[, ]+([A-Za-z\u4e00-\u9fa5]+)\b/i.test(text)) return true;
  return false;
}

/* ===================== Component ===================== */
export default function LiveConversation() {
  // â€”â€” è¡¨å• â€”â€” //
  const [mode, setMode] = useState("face-to-face");
  const [background, setBackground] = useState("");
  const [speakerRole, setSpeakerRole] = useState("");

  // åŠ¨æ€èº«ä»½
  const [myName, setMyName] = useState("Lucy"); // é»˜è®¤å€¼ï¼Œéšæ—¶å¯æ”¹
  const [autoNameFromGuide, setAutoNameFromGuide] = useState(true);

  // å¤–æ”¾é˜²å›å£°æ¨¡å¼ï¼ˆæ‰“/æ¥ç”µè¯å»ºè®®å¼€å¯ï¼‰
  const [speakerMode, setSpeakerMode] = useState(true);

  // â€”â€” å¯¹è¯ä¸æ§åˆ¶ â€”â€” //
  const [conversation, setConversation] = useState<ChatMessage[]>([]);
  const [isActive, setIsActive] = useState(false);

  // è¯†åˆ«/æ’­æŠ¥æ§åˆ¶
  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const isSpeakingRef = useRef(false);
  const correctedOnceRef = useRef(false);
  const manualInputsRef = useRef<string[]>([]);
  const lastResultAtRef = useRef<number>(0);
  const heartbeatTimerRef = useRef<number | null>(null);

  // å›å£°è¿‡æ»¤ï¼šè®°å½•æœ€è¿‘ 3 æ¡ AI å›å¤
  const recentAIRef = useRef<string[]>([]);

  // åªå¤„ç†æœ€ç»ˆç»“æœï¼›é˜²é‡å¤
  const lastFinalTextRef = useRef<string>("");

  // æ’­æŠ¥åå¿½ç•¥çª—å£ï¼šé‡å¯è¯†åˆ«åçš„ä¸€å°æ®µæ—¶é—´å†…ä¸¢å¼ƒä»»ä½•ç»“æœ
  const listeningResumedAtRef = useRef<number>(0);
  const markListeningResumed = () => { listeningResumedAtRef.current = Date.now(); };

  // æ ¹æ® GUIDE è‡ªåŠ¨æ›´æ–°åå­—ï¼ˆå¯å…³é—­ï¼‰
  useEffect(() => {
    if (!autoNameFromGuide) return;
    const n = extractNameFromGuide(background);
    if (n && n !== myName) setMyName(n);
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [background, autoNameFromGuide]);

  /* è¯†åˆ«å™¨ */
  const ensureRecognition = () => {
    if (recognitionRef.current) return recognitionRef.current;

    const SR: any = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SR) {
      console.error("This browser does not support Web Speech API.");
      return null;
    }

    const recog: SpeechRecognition = new SR();
    recog.lang = "en-US";        // åˆå§‹å›ºå®šè‹±æ–‡
    recog.interimResults = true; // å…è®¸ä¸­é—´ç»“æœï¼Œä½†æˆ‘ä»¬åªåƒ isFinal
    recog.continuous = true;

    recog.onresult = async (event: SpeechRecognitionEvent) => {
      if (!isActive) return;
      if (isSpeakingRef.current) return;

      // æ’­æŠ¥åˆšç»“æŸåçš„å¿½ç•¥çª—å£ï¼ˆå¤–æ”¾ç¨é•¿ï¼‰
      const IGNORE_WINDOW_MS = speakerMode ? 1800 : 1200;
      if (Date.now() - listeningResumedAtRef.current < IGNORE_WINDOW_MS) return;

      lastResultAtRef.current = Date.now();

      // å–æœ€åä¸€ä¸ª isFinal=true çš„ç»“æœ
      let finalText = "";
      for (let i = event.results.length - 1; i >= 0; i--) {
        const res: any = event.results[i];
        if (res.isFinal) {
          finalText = res[0]?.transcript?.trim?.() || "";
          break;
        }
      }
      if (!finalText) return;

      // åªåŸºäºå½“å‰æ–‡æœ¬åˆ‡è¯­è¨€ï¼ˆå«ä¸­æ–‡æ‰åˆ‡ä¸­æ–‡ï¼‰
      const want = pickASRLang(finalText);
      if (recog.lang !== want) {
        try { recog.stop(); } catch {}
        recog.lang = want;
        try { recog.start(); markListeningResumed(); } catch {}
      }

      // å»é‡ï¼šå’Œä¸Šæ¬¡â€œæœ€ç»ˆæ–‡æœ¬â€å‡ ä¹ä¸€è‡´å°±ä¸¢å¼ƒ
      const lastFinal = lastFinalTextRef.current;
      const almostSame =
        finalText === lastFinal ||
        (finalText.length > 5 &&
          lastFinal.length > 5 &&
          (finalText.startsWith(lastFinal) || lastFinal.startsWith(finalText)));
      if (almostSame) return;
      lastFinalTextRef.current = finalText;

      // å›å£°è¿‡æ»¤ï¼šä¸æœ€è¿‘ AI å›å¤é«˜åº¦ç›¸ä¼¼ -> ä¸¢å¼ƒ
      const echoThreshold = speakerMode ? 0.50 : 0.55;
      if (isEchoOfAI(finalText, recentAIRef.current, echoThreshold)) {
        return;
      }

      // Create bilingual message for partner's speech
      const partnerBilingual = await toBilingual(finalText);
      const partnerMsg: ChatMessage = {
        id: `partner-${Date.now()}`,
        role: "user",
        contentEN: partnerBilingual.en,
        contentZH: partnerBilingual.zh,
        timestamp: Date.now(),
      };
      setConversation((prev) => [...prev, partnerMsg]);

      // â€”â€” åå­—è¯¯å«ï¼Œä»…çº ä¸€æ¬¡ â€”â€” //
      const mustCorrectOnce = detectMisname(finalText, myName) && !correctedOnceRef.current;

      // â€”â€” è½»é‡ä¸Šä¸‹æ–‡ â€”â€” //
      const recent = conversation.slice(-4).map(msg =>
        `${msg.role === 'user' ? 'ğŸ§‘ Partner' : 'ğŸ¤– AI'}: ${msg.contentEN}`
      ).join("\n") || "(none)";

      // â€”â€” ç³»ç»Ÿæç¤ºï¼ˆåŠ¨æ€èº«ä»½ + è‹±æ–‡ï¼‰ â€”â€” //
      const persona = (myName || "Speaker").trim();
      const systemMessage = `
You are my real-time voice proxy. Always reply in ENGLISH (even if inputs are Chinese).
Your persona name is "${persona}". NEVER claim to be anyone else.
If the partner misnames you, correct ONCE with: "Hi â€” this is ${persona}." then continue.
Do NOT reveal you are an assistant. Be natural, concise, professional (1â€“3 sentences).
Avoid repeating the same point; move the conversation forward with one crisp question or update.
Never echo my manual notes verbatim; paraphrase naturally.

GUIDE (verbatim if present):
${background ? `"""\n${background}\n"""` : "(empty)"}

Context:
- Mode: ${mode || "N/A"}
- Counterparty: ${speakerRole || "N/A"}
`.trim();

      const userMessage = `
Recent lines:
${recent}

New partner line:
${finalText}

Task:
1) Reply in ENGLISH only, first-person as ${persona}, 1â€“3 sentences.
2) If this line is another greeting, transition to ONE concrete topic rather than repeating greetings.
3) Paraphrase; do not mirror the user's words.
`.trim();

      let finalUserMessage = userMessage;
      if (mustCorrectOnce) {
        finalUserMessage += `\nAlso: Begin with exactly: "Hi â€” this is ${persona}." once, then continue.`;
      }

      try {
        const reply = await getAIResponse({ systemMessage, userMessage: finalUserMessage });

        // è®°å½•æœ€è¿‘ 3 æ¡ AI å›å¤ï¼Œä¾›å›å£°è¿‡æ»¤
        recentAIRef.current = [reply, ...recentAIRef.current].slice(0, 3);

        // Translate AI's English reply to Chinese
        const aiZH = await toBilingual(reply).then(b => b.zh);
        const aiMsg: ChatMessage = {
          id: `ai-${Date.now()}`,
          role: "assistant",
          contentEN: reply,
          contentZH: aiZH,
          timestamp: Date.now(),
        };
        setConversation((prev) => [...prev, aiMsg]);

        // â€”â€” æ’­æŠ¥çª—å£é”å®šï¼ˆå¤–æ”¾å¤šåŠ ç¼“å†²ï¼‰ â€”â€” //
        const recog2 = recognitionRef.current;
        const safeReply = sanitizeForTTS(reply, manualInputsRef.current);
        const speakMs = estimateTtsMs(safeReply);
        const extra = speakerMode ? 700 : 300;
        isSpeakingRef.current = true;
        try { recog2?.stop(); } catch {}
        await speakWithElevenLabs(safeReply);
        await new Promise((r) => setTimeout(r, speakMs + extra));
      } catch (e) {
        console.error("âŒ generate/speak error:", e);
      } finally {
        isSpeakingRef.current = false;
        try { recognitionRef.current?.start(); markListeningResumed(); } catch {}
      }

      if (mustCorrectOnce) correctedOnceRef.current = true;
    };

    recog.onerror = (e: any) => {
      console.error("recognition.onerror:", e?.error || e);
    };

    recog.onend = () => {
      if (isActive && !isSpeakingRef.current) {
        try { recognitionRef.current?.start(); markListeningResumed(); } catch {}
      }
    };

    recognitionRef.current = recog;
    return recog;
  };

  const safeStart = () => { try { ensureRecognition()?.start(); markListeningResumed(); } catch {} };
  const safeStop = () => { try { recognitionRef.current?.stop(); } catch {} };
  const destroyRecognition = () => {
    try {
      if (recognitionRef.current) {
        (recognitionRef.current as any).onresult = null;
        (recognitionRef.current as any).onend = null;
        (recognitionRef.current as any).onerror = null;
        try { recognitionRef.current.stop(); } catch {}
      }
    } finally { recognitionRef.current = null; }
  };

  // mic æƒé™ + å›å£°/é™å™ªï¼ˆå¤–æ”¾ä¹Ÿæœ‰å¸®åŠ©ï¼‰
  useEffect(() => {
    navigator.mediaDevices.getUserMedia({
      audio: { echoCancellation: true, noiseSuppression: true, autoGainControl: false } as any
    })
      .then(() => console.log("ğŸ¤ mic granted"))
      .catch(() => alert("âŒ Microphone permission denied"));
  }, []);

  // å¿ƒè·³å…œåº•ï¼š20s æ— ç»“æœ -> å¼ºåˆ¶é‡å¯å¹¶åˆ‡å›è‹±æ–‡
  useEffect(() => {
    if (!isActive) return;
    lastResultAtRef.current = Date.now();
    heartbeatTimerRef.current = window.setInterval(() => {
      if (!isActive) return;
      const idleMs = Date.now() - lastResultAtRef.current;
      if (idleMs > 20000 && !isSpeakingRef.current) {
        try { recognitionRef.current?.stop(); } catch {}
        try {
          if (recognitionRef.current) (recognitionRef.current as any).lang = "en-US";
          recognitionRef.current?.start();
          markListeningResumed();
        } catch {}
      }
    }, 5000) as unknown as number;

    return () => {
      if (heartbeatTimerRef.current) {
        clearInterval(heartbeatTimerRef.current as number);
        heartbeatTimerRef.current = null;
      }
    };
  }, [isActive]);

  // å¼€/åœ
  useEffect(() => {
    if (isActive) {
      correctedOnceRef.current = false;
      recentAIRef.current = [];
      lastFinalTextRef.current = "";
      const recog = ensureRecognition();
      if (recog) (recog as any).lang = "en-US"; // å¯åŠ¨å›ºå®šè‹±æ–‡
      safeStart();
    } else {
      safeStop();
      destroyRecognition();
    }
    // eslint-disable-next-line react-hooks/exhaustive-deps
  }, [isActive]);

  // å¯¼å‡ºå¯¹è¯è®°å½•ä¸º .txt æ–‡ä»¶
  const exportConversation = () => {
    if (conversation.length === 0) return;

    // Format bilingual messages for export
    const content = conversation.map(msg => {
      const role = msg.role === "user" ? "ğŸ§‘ You" : "ğŸ¤– AI";
      const isChinese = hasChinese(msg.contentZH);
      // Show original language first, then translation
      if (isChinese) {
        return `${role} (ZH): ${msg.contentZH}\n${role} (EN): ${msg.contentEN}`;
      } else {
        return `${role} (EN): ${msg.contentEN}\n${role} (ZH): ${msg.contentZH}`;
      }
    }).join("\n\n");

    // ç”Ÿæˆæ—¶é—´æˆ³ï¼š2025-11-24-16-30-05 æ ¼å¼
    const now = new Date();
    const timestamp = now
      .toISOString()
      .replace(/T/, "-")
      .replace(/:/g, "-")
      .split(".")[0];

    const blob = new Blob([content], { type: "text/plain;charset=utf-8" });
    const url = URL.createObjectURL(blob);

    const a = document.createElement("a");
    a.href = url;
    a.download = `ai-secretary-conversation-${timestamp}.txt`;
    document.body.appendChild(a);
    a.click();
    document.body.removeChild(a);

    URL.revokeObjectURL(url);
  };

  // æ‰‹åŠ¨è¾“å…¥ï¼šä¸æ’­æŠ¥æ‰‹åŠ¨æ–‡æœ¬
  const handleManualSend = async (text: string) => {
    if (!text?.trim()) return;

    // Create bilingual message for manual input
    const manualBilingual = await toBilingual(text);
    const manualMsg: ChatMessage = {
      id: `manual-${Date.now()}`,
      role: "user",
      contentEN: manualBilingual.en,
      contentZH: manualBilingual.zh,
      timestamp: Date.now(),
      isManual: true,
    };
    setConversation((prev) => [...prev, manualMsg]);
    manualInputsRef.current = [text, ...manualInputsRef.current].slice(0, 5);

    const recent = conversation.slice(-4).map(msg =>
      `${msg.role === 'user' ? `ğŸ§‘ ${myName || "Me"}` : 'ğŸ¤– AI'}: ${msg.contentEN}`
    ).join("\n") || "(none)";

    const persona = (myName || "Speaker").trim();
    const systemMessage = `
You are my real-time voice proxy. Always reply in ENGLISH (even if inputs are Chinese).
Your persona name is "${persona}". Never claim to be anyone else.
Be natural, concise, professional (1â€“3 sentences). Progress the talk with one crisp point.
Do not echo my manual note verbatim; paraphrase.
`.trim();

    const userMessage = `
Recent lines:
${recent}

My manual note:
${text}

Task:
1) Reply in English only, first-person as ${persona}, 1â€“3 sentences.
2) Paraphrase my note; don't mirror wording.
3) Ask one precise follow-up if helpful.
`.trim();

    try {
      const reply = await getAIResponse({ systemMessage, userMessage });
      recentAIRef.current = [reply, ...recentAIRef.current].slice(0, 3);

      // Translate AI's English reply to Chinese
      const aiZH = await toBilingual(reply).then(b => b.zh);
      const aiMsg: ChatMessage = {
        id: `ai-manual-${Date.now()}`,
        role: "assistant",
        contentEN: reply,
        contentZH: aiZH,
        timestamp: Date.now(),
      };
      setConversation((prev) => [...prev, aiMsg]);

      // æ’­æŠ¥ï¼ˆé”å®šçª—å£ï¼›å¤–æ”¾å¤šåŠ ç¼“å†²ï¼‰
      const recog = ensureRecognition();
      isSpeakingRef.current = true;
      try { recog?.stop(); } catch {}
      const safeReply = sanitizeForTTS(reply, manualInputsRef.current);
      const speakMs = estimateTtsMs(safeReply);
      const extra = speakerMode ? 700 : 300;
      await speakWithElevenLabs(safeReply);
      await new Promise((r) => setTimeout(r, speakMs + extra));
    } catch (e) {
      console.error(e);
    } finally {
      isSpeakingRef.current = false;
      if (isActive) safeStart();
    }
  };

  return (
    <div className="p-4 space-y-4">
      <h2 className="text-xl font-semibold">AI Secretary â€” Live Conversation</h2>

      <div className="grid gap-3 md:grid-cols-4">
        <div>
          <label className="block text-sm mb-1">Mode æ¨¡å¼</label>
          <select
            className="w-full border rounded px-2 py-1"
            value={mode}
            onChange={(e) => setMode(e.target.value)}
            disabled={isActive}
          >
            <option value="face-to-face">Face to Face å½“é¢æ²Ÿé€š</option>
            <option value="call-out">Call Out ä¸»åŠ¨æ‰“ç”µè¯</option>
            <option value="call-in">Call In æ¥å¬æ¥ç”µ</option>
          </select>
        </div>

        <div>
          <label className="block text-sm mb-1">My Name æˆ‘çš„èº«ä»½</label>
          <input
            className="w-full border rounded px-2 py-1"
            placeholder="ä¾‹å¦‚ï¼šJamesçš„çˆ¸çˆ¸ / e.g. James' father"
            value={myName}
            onChange={(e) => setMyName(e.target.value)}
            disabled={isActive || autoNameFromGuide}
          />
          <label className="inline-flex items-center gap-2 mt-1 text-xs">
            <input
              type="checkbox"
              checked={autoNameFromGuide}
              onChange={(e) => setAutoNameFromGuide(e.target.checked)}
              disabled={isActive}
            />
            è‡ªåŠ¨ä» GUIDE æå– / Auto from GUIDE
          </label>
        </div>

        <div>
          <label className="block text-sm mb-1">Counterparty å¯¹æ–¹èº«ä»½</label>
          <input
            className="w-full border rounded px-2 py-1"
            placeholder="ä¾‹å¦‚ï¼šæ€¥è¯Šç§‘åŒ»ç”Ÿ / e.g. ER doctor"
            value={speakerRole}
            onChange={(e) => setSpeakerRole(e.target.value)}
            disabled={isActive}
          />
        </div>

        <div className="flex items-end justify-between">
          <label className="inline-flex items-center gap-2 text-sm">
            <input
              type="checkbox"
              checked={speakerMode}
              onChange={(e) => setSpeakerMode(e.target.checked)}
              disabled={isActive}
            />
            æ‰¬å£°å™¨æ¨¡å¼ï¼ˆé˜²å›å£°ï¼‰ / Speakerphone Mode (Echo Shield)
          </label>
          <button
            className={`px-3 py-2 rounded text-white ${isActive ? "bg-red-500" : "bg-green-600"}`}
            onClick={() => setIsActive((v) => !v)}
          >
            {isActive ? "åœæ­¢ Stop" : "å¼€å§‹ Start"}
          </button>
        </div>
      </div>

      <div>
        <label className="block text-sm mb-1 font-medium">GUIDE / Background èƒŒæ™¯è¯´æ˜</label>

        {/* æ–‡ä»¶ä¸Šä¼ æ§ä»¶ */}
        <div className="mb-2">
          <input
            type="file"
            accept=".txt,.md,.rtf,.text"
            className="text-sm"
            onChange={(e) => {
              const file = e.target.files?.[0];
              if (!file) return;

              const reader = new FileReader();
              reader.onload = (event) => {
                let raw = String(event.target?.result || "");

                // ç»Ÿä¸€æ¢è¡Œç¬¦
                raw = raw.replace(/\r\n/g, "\n");
                // å»æ‰ BOM
                raw = raw.replace(/^\uFEFF/, "");

                // æŒ‰ç©ºè¡Œåˆ†æ®µ
                const parts = raw.split(/\n\s*\n/);
                let cleaned: string;
                if (parts.length > 1) {
                  // è·³è¿‡ç¬¬ä¸€æ®µï¼ˆæ ‡é¢˜ï¼‰ï¼Œä½¿ç”¨åé¢çš„æ­£æ–‡
                  cleaned = parts.slice(1).join("\n\n").trimStart();
                } else {
                  // æ²¡æœ‰ç©ºè¡Œï¼Œé€€åŒ–ä¸ºåŸæ¥çš„è¡Œä¸º
                  cleaned = raw.trimStart();
                }

                setBackground(cleaned);
              };
              reader.onerror = () => {
                alert("æ–‡ä»¶è¯»å–å¤±è´¥ï¼Œè¯·é‡è¯•ã€‚");
              };
              reader.readAsText(file, "utf-8");

              // æ¸…ç©º inputï¼Œå…è®¸é‡å¤ä¸Šä¼ åŒä¸€æ–‡ä»¶
              e.target.value = "";
            }}
            disabled={isActive}
          />
          <p className="text-xs text-gray-500 mt-1">
            å¯é€‰æ‹©æœ¬åœ° .txt/.md/.rtf æ–‡ä»¶å¯¼å…¥ç—…æƒ…/èƒŒæ™¯è¯´æ˜
          </p>
        </div>

        <textarea
          className="w-full border rounded px-2 py-2 h-32"
          placeholder="åœ¨è¿™é‡Œç®€è¦å†™æ˜ç—…æƒ…æˆ–èƒŒæ™¯ï¼ŒAI ä¼šæŒ‰ç…§è¿™é‡Œçš„å†…å®¹æ¥å›ç­”ã€‚ä¹Ÿå¯ä»¥ä¸Šæ–¹å¯¼å…¥ .txt æ–‡ä»¶ã€‚ / Briefly describe the situation here, or import a .txt file above."
          value={background}
          onChange={(e) => setBackground(e.target.value)}
          disabled={isActive}
        />
      </div>

      <div className="flex items-center justify-between mb-2">
        <h3 className="text-sm font-medium">å¯¹è¯è®°å½• Conversation</h3>
        <button
          className="px-3 py-1 rounded text-sm bg-blue-500 text-white hover:bg-blue-600 disabled:opacity-50 disabled:cursor-not-allowed"
          onClick={exportConversation}
          disabled={conversation.length === 0}
        >
          å¯¼å‡ºä¸ºæ–‡æœ¬ Export .txt
        </button>
      </div>

      <div className="border rounded p-3 bg-white">
        {conversation.map((msg, idx) => {
          const isUser = msg.role === "user";
          const isAI = msg.role === "assistant";
          const isChinese = hasChinese(msg.contentZH);

          // Determine display order: original first, then translation
          let firstLang: string, firstContent: string;
          let secondLang: string, secondContent: string;

          if (isAI) {
            // AI messages: always EN first, then ZH
            firstLang = "EN";
            firstContent = msg.contentEN;
            secondLang = "ZH";
            secondContent = msg.contentZH;
          } else {
            // User messages: original language first
            if (isChinese) {
              firstLang = "ZH";
              firstContent = msg.contentZH;
              secondLang = "EN";
              secondContent = msg.contentEN;
            } else {
              firstLang = "EN";
              firstContent = msg.contentEN;
              secondLang = "ZH";
              secondContent = msg.contentZH;
            }
          }

          const roleLabel = isUser
            ? (msg.isManual ? `ğŸ§‘ ${myName || "You"} (manual)` : "ğŸ§‘ Partner")
            : "ğŸ¤– AI";

          return (
            <div key={msg.id || idx} className="mb-3 leading-7">
              <div className="whitespace-pre-wrap">
                {roleLabel} ({firstLang}): {firstContent}
              </div>
              <div className="whitespace-pre-wrap text-gray-600">
                {roleLabel} ({secondLang}): {secondContent}
              </div>
            </div>
          );
        })}
      </div>

      <ManualInputBox onSend={handleManualSend} />
    </div>
  );
}
