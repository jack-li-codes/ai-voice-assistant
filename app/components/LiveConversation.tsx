// âœ… æœ€ç»ˆç¨³å®šä¿®å¤ç‰ˆ LiveConversation.tsxï¼ˆå·²è§£å†³è¯†åˆ«å™¨æ— æ³•é‡å¯ + å¤šè½®è¯†åˆ«ä¸ç”Ÿæ•ˆé—®é¢˜ï¼‰

'use client';

import { useEffect, useRef, useState } from 'react';
import { getAIResponse } from '@/lib/gpt/getAIResponse';
import { speakWithElevenLabs } from '@/lib/voice/speakWithElevenLabs';

declare global {
  interface Window {
    webkitSpeechRecognition: any;
    SpeechRecognition: any;
  }
  interface SpeechRecognitionEvent extends Event {
    results: SpeechRecognitionResultList;
  }
}

export default function LiveConversation() {
  const [mode, setMode] = useState('face-to-face');
  const [background, setBackground] = useState('');
  const [speakerRole, setSpeakerRole] = useState('');
  const [conversation, setConversation] = useState<string[]>([]);
  const [isActive, setIsActive] = useState(false);
  const recognitionRef = useRef<any>(null);
  const isSpeakingRef = useRef(false);

  // åˆå§‹åŒ–è¯†åˆ«å™¨
  const createNewRecognition = () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    const recognition = new SpeechRecognition();
    recognition.lang = 'zh-CN';
    recognition.interimResults = false;
    recognition.continuous = true;
    return recognition;
  };

  const restartRecognition = () => {
    const newRecog = createNewRecognition();

    newRecog.onstart = () => console.log('âœ… recognition.onstart è¢«è§¦å‘ï¼Œç›‘å¬å·²å¼€å¯');

    newRecog.onresult = async (event: SpeechRecognitionEvent) => {
      if (isSpeakingRef.current || !isActive) return;
      const userText = event.results[event.results.length - 1][0].transcript;
      setConversation((prev) => [...prev, `ğŸ§‘ å¯¹æ–¹: ${userText}`]);

      const systemPrompt = `
ä½ æ˜¯Jamesçš„çˆ¸çˆ¸ï¼Œè¯·ä»¥ä»–çš„èº«ä»½ç”¨è‡ªç„¶æµç•…ã€ä¸“ä¸šç¤¼è²Œçš„è‹±æ–‡å›ç­”åŒ»ç”Ÿçš„é—®é¢˜ã€‚ä¸è¦è§£é‡Šä½ æ˜¯è°ï¼Œä¸è¦æåŠAIæˆ–ç§˜ä¹¦ã€‚è¯·å§‹ç»ˆå‚è€ƒä»¥ä¸‹èƒŒæ™¯ä¿¡æ¯åå†ä½œç­”ï¼š

ğŸ¯ èƒŒæ™¯è¯´æ˜:
- å½“å‰æ²Ÿé€šæ¨¡å¼: ${mode}
- å¯¹æ–¹èº«ä»½: ${speakerRole}
- åœºæ™¯èƒŒæ™¯: ${background}

ğŸ’¬ åŒ»ç”Ÿåˆšæ‰è¯´: ${userText}

ğŸ§  ä½ çš„ä»»åŠ¡:
- åªä»£è¡¨Jamesçš„çˆ¸çˆ¸å›ç­”ã€‚
- ç”¨æ¸…æ™°ã€çœŸå®ã€ç®€æ´çš„è‹±æ–‡è¡¨è¾¾ã€‚
- ä¸è¦é‡å¤èƒŒæ™¯ä¿¡æ¯ï¼Œä¸è¦è§£é‡Šèº«ä»½ã€‚
- å›åº”åŒ»ç”Ÿåˆšåˆšé‚£å¥è¯ï¼Œä¸è¦ä¸€æ¬¡è¯´å¤ªå¤šã€‚
      `;

      const reply = await getAIResponse(systemPrompt);
      setConversation((prev) => [...prev, `ğŸ¤– AI: ${reply}`]);

      if (recognitionRef.current) recognitionRef.current.stop();
      isSpeakingRef.current = true;
      console.log('ğŸ—£ å¼€å§‹æ’­æ”¾è¯­éŸ³...');

      try {
        await speakWithElevenLabs(reply);
        console.log('âœ… è¯­éŸ³æ’­æ”¾æˆåŠŸ');
      } catch (error) {
        console.error('âŒ è¯­éŸ³æ’­æ”¾å¤±è´¥:', error);
      } finally {
        isSpeakingRef.current = false;
        console.log('âœ… isSpeakingRef é‡ç½®ä¸º falseï¼Œå‡†å¤‡é‡å¯è¯†åˆ«å™¨');
        restartRecognition();
        recognitionRef.current.start();
      }
    };

    newRecog.onerror = (event: any) => {
      console.error('âŒ recognition.onerror:', event.error);
    };

    newRecog.onend = () => {
      console.log('ğŸ“£ onend è¢«åŠ¨è§¦å‘ï¼ŒisActive:', isActive, '| isSpeakingRef:', isSpeakingRef.current);
      if (isActive && !isSpeakingRef.current) {
        try {
          newRecog.start();
          console.log('âœ… è¢«åŠ¨é‡å¯è¯†åˆ«æˆåŠŸ');
        } catch (err) {
          console.error('âŒ è¢«åŠ¨è¯†åˆ«é‡å¯å¤±è´¥:', err);
        }
      }
    };

    recognitionRef.current = newRecog;
  };

  useEffect(() => {
    navigator.mediaDevices
      .getUserMedia({ audio: true })
      .then(() => console.log('ğŸ¤ éº¦å…‹é£æƒé™å·²è·å–'))
      .catch(() => alert('âŒ è·å–éº¦å…‹é£å¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™'));
  }, []);

  useEffect(() => {
    if (isActive) {
      restartRecognition();
      try {
        recognitionRef.current?.start();
        console.log('ğŸ§ æ­£åœ¨å¯åŠ¨è¯†åˆ«...');
      } catch (error) {
        console.error('âŒ å¯åŠ¨è¯†åˆ«å¤±è´¥:', error);
      }
    } else {
      recognitionRef.current?.stop();
    }
  }, [isActive]);

  return (
    <div className="space-y-4">
      <h1 className="text-xl font-bold text-blue-700">AI ç§˜ä¹¦è¯­éŸ³å¯¹è¯æµ‹è¯•</h1>

      <div className="space-y-2">
        <label className="block text-sm font-medium">ä½¿ç”¨æ¨¡å¼</label>
        <select
          value={mode}
          onChange={(e) => setMode(e.target.value)}
          className="border px-3 py-2 rounded w-full"
        >
          <option value="face-to-face">é¢å¯¹é¢æ²Ÿé€š</option>
          <option value="make-call">æ‹¨æ‰“ç”µè¯</option>
          <option value="receive-call">æ¥å¬ç”µè¯</option>
        </select>
      </div>

      <div>
        <label className="block text-sm font-medium">èƒŒæ™¯ä¿¡æ¯</label>
        <textarea
          value={background}
          onChange={(e) => setBackground(e.target.value)}
          placeholder="è¯·è¾“å…¥èƒŒæ™¯ä¿¡æ¯ï¼Œä¾‹å¦‚ä½ å½“å‰çš„ä½ç½®ã€èº«ä»½ã€ç›®çš„ç­‰"
          className="border px-3 py-2 rounded w-full"
        />
      </div>

      <div>
        <label className="block text-sm font-medium">å¯¹æ–¹æ˜¯è°ï¼ˆåŒ»ç”Ÿ/è€å¸ˆ/é“¶è¡Œâ€¦ï¼‰</label>
        <input
          value={speakerRole}
          onChange={(e) => setSpeakerRole(e.target.value)}
          placeholder="å¦‚ åŒ»ç”Ÿ"
          className="border px-3 py-2 rounded w-full"
        />
      </div>

      <button
        onClick={() => setIsActive((v) => !v)}
        className={`px-4 py-2 rounded text-white ${isActive ? 'bg-red-500' : 'bg-green-600'}`}
      >
        {isActive ? 'ğŸ›‘ åœæ­¢å¯¹è¯' : 'ğŸ¤ å¯åŠ¨å¯¹è¯'}
      </button>

      <div className="bg-gray-100 p-4 rounded space-y-2 h-64 overflow-y-auto">
        {conversation.map((line, idx) => (
          <div key={idx}>{line}</div>
        ))}
      </div>
    </div>
  );
}
