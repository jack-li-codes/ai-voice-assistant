"use client";

import { useState, useRef, useEffect } from "react";
import ChatBubble from "./ChatBubble";
import { Button } from "@/components/ui/button";
import { speakWithElevenLabs } from "@/lib/tts";

type Message = {
  sender: "user" | "ai";
  text: string;
  isLoading?: boolean;
};

// @ts-ignore
const SpeechRecognition =
  typeof window !== "undefined" &&
  ((window as any).SpeechRecognition || (window as any).webkitSpeechRecognition);

export default function VoiceAssistant() {
  const [isRecording, setIsRecording] = useState(false);
  const [messages, setMessages] = useState<Message[]>([]);
  const messagesEndRef = useRef<HTMLDivElement>(null);

  const scrollToBottom = () => {
    messagesEndRef.current?.scrollIntoView({ behavior: "smooth" });
  };

  useEffect(() => {
    scrollToBottom();
  }, [messages]);

  const handleClick = () => {
    if (!SpeechRecognition) {
      alert("ä½ çš„æµè§ˆå™¨ä¸æ”¯æŒè¯­éŸ³è¯†åˆ«ï¼Œè¯·ä½¿ç”¨ Chrome æµè§ˆå™¨");
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.lang = "zh-CN";
    recognition.continuous = false;
    recognition.interimResults = false;

    recognition.onstart = () => {
      setIsRecording(true);
    };

    recognition.onresult = async (event: any) => {
      try {
        const text = event.results[0][0].transcript;
        if (!text) return;

        setMessages((prev) => [
          ...prev,
          { sender: "user", text },
          { sender: "ai", text: "", isLoading: true },
        ]);

        const res = await fetch("/api/chat", {
          method: "POST",
          headers: { "Content-Type": "application/json" },
          body: JSON.stringify({ prompt: text }),
        });

        if (!res.ok) {
          throw new Error(`GPT è¯·æ±‚å¤±è´¥: ${res.status}`);
        }

        const data = await res.text();

        setMessages((prev) => {
          const updated = [...prev];
          const aiIndex = updated.findIndex((m, i) => i === updated.length - 1 && m.sender === "ai" && m.isLoading);
          if (aiIndex !== -1) {
            updated[aiIndex] = { sender: "ai", text: data };
          }
          return updated;
        });

        await speakWithElevenLabs(data);
      } catch (error) {
        console.error("å‡ºé”™:", error);
        setMessages((prev) => [
          ...prev.filter((m) => !m.isLoading),
          { sender: "ai", text: "æŠ±æ­‰ï¼ŒAI æš‚æ—¶æ— æ³•å›ç­”ï¼Œè¯·ç¨åå†è¯•ã€‚" },
        ]);
      }
    };

    recognition.onerror = (event: any) => {
      console.error("è¯­éŸ³è¯†åˆ«å‡ºé”™:", event.error);
      alert("è¯­éŸ³è¯†åˆ«å‡ºé”™ï¼š" + event.error);
      setIsRecording(false);
    };

    recognition.onend = () => {
      setIsRecording(false);
    };

    recognition.start();
  };

  return (
    <div className="bg-gray-50 min-h-screen flex flex-col items-center justify-start p-6 space-y-6">
      <h1 className="text-4xl font-bold text-gray-900">AI é¢è¯•åŠ©æ‰‹</h1>

      <Button
        onClick={handleClick}
        size="lg"
        className={`$${
          isRecording ? "bg-red-600 hover:bg-red-700" : "bg-blue-600 hover:bg-blue-700"
        } text-white px-8 py-6 rounded-lg text-lg shadow-md transition-colors`}
      >
        ğŸ¤ {isRecording ? "æ­£åœ¨å½•éŸ³..." : "ç‚¹å‡»å¼€å§‹è¯´è¯"}
      </Button>

      {isRecording && (
        <div className="flex justify-center space-x-2">
          <div className="w-2 h-2 bg-blue-600 rounded-full animate-bounce" style={{ animationDelay: '0ms' }} />
          <div className="w-2 h-2 bg-blue-600 rounded-full animate-bounce" style={{ animationDelay: '150ms' }} />
          <div className="w-2 h-2 bg-blue-600 rounded-full animate-bounce" style={{ animationDelay: '300ms' }} />
        </div>
      )}

      <div className="max-w-2xl w-full mx-auto space-y-4 px-4">
        {messages.map((msg, idx) => (
          <ChatBubble key={idx} sender={msg.sender} text={msg.text} isLoading={msg.isLoading} />
        ))}
        <div ref={messagesEndRef} />
      </div>
    </div>
  );
}
